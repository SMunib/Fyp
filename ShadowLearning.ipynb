{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-iTTeH-YLNO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from joblib import dump, load\n",
        "import pandas\n",
        "import numpy\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "class ShadowLearning:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def scaler(self, values):\n",
        "        min_value = values.min()\n",
        "        max_value = values.max()\n",
        "\n",
        "        scaled_distances = (values - min_value) / (max_value - min_value)\n",
        "        return scaled_distances\n",
        "\n",
        "    def roundToNearestBins(self, values):\n",
        "        values = numpy.array(values).reshape(-1, 1)\n",
        "        bins = numpy.arange(0.000, 1.050, 0.025)\n",
        "        bins = numpy.array(bins).reshape(1, -1)\n",
        "\n",
        "        abs_diff = numpy.abs(values - bins)\n",
        "\n",
        "        min_indices = numpy.argmin(abs_diff, axis=1)\n",
        "\n",
        "        return bins[0, min_indices]\n",
        "\n",
        "    def refineData(self, df: pandas.core.frame.DataFrame):\n",
        "        pass\n",
        "\n",
        "    def optimizer(self, df: pandas.core.frame.DataFrame, x: list[str], y: str):\n",
        "        pass\n",
        "\n",
        "    def fit(self, df: pandas.core.frame.DataFrame,  x: list[str], y: str, save_files: bool = True):\n",
        "        # Checking paramters are of required type\n",
        "        if not(isinstance(df, pandas.core.frame.DataFrame)):\n",
        "            raise TypeError(\"DataFrame provided is not of type pandas.core.frame.DataFrame\")\n",
        "\n",
        "        if not (isinstance(x, list) and all(isinstance(item, str) for item in x)):\n",
        "            raise TypeError(\"Provided features list is not of of type list[str]\")\n",
        "\n",
        "        if not(isinstance(y, str)):\n",
        "            raise TypeError(\"Provided target column is not of type str\")\n",
        "\n",
        "        #Initializing and Training the model on initial data\n",
        "        model = SGDRegressor(\n",
        "            max_iter=3,\n",
        "            warm_start=True,\n",
        "            penalty='l2',\n",
        "            alpha=0.01,\n",
        "            learning_rate='constant',\n",
        "            eta0=0.01\n",
        "            )\n",
        "        scaler = MinMaxScaler()\n",
        "\n",
        "        X = df[x]\n",
        "        Y = df[y]\n",
        "\n",
        "        model.partial_fit(X, Y)\n",
        "\n",
        "        weights = model.coef_\n",
        "        intercept = model.intercept_\n",
        "\n",
        "        numerator = numpy.abs(numpy.dot(X, weights) + intercept - Y)\n",
        "        denominator = numpy.sqrt(numpy.sum(weights ** 2))\n",
        "        distances_from_fit = numerator / denominator\n",
        "        distances_from_fit = scaler.fit_transform(numpy.array(distances_from_fit).reshape(-1, 1))\n",
        "        distribution = self.roundToNearestBins(distances_from_fit)\n",
        "\n",
        "        target_values = numpy.arange(0.000, 1.050, 0.025)\n",
        "\n",
        "        distribution = [round(x, 3) for x in distribution]\n",
        "        counts_dict = {numpy.around(val, decimals=3): 0 for val in target_values}\n",
        "        counts_dict.update(Counter(distribution))\n",
        "\n",
        "        # Saving the model and distribution file\n",
        "        if save_files:\n",
        "            dump(model, 'shadow_fit.pkl')\n",
        "            dump(scaler, 'shadow_scaler.pkl')\n",
        "            with open('shadow_distribution.json', 'w') as f:\n",
        "                json.dump(counts_dict, f, indent=4)\n",
        "\n",
        "        return model, counts_dict\n",
        "\n",
        "    def filter(self, df: pandas.core.frame.DataFrame, x: list[str], y: str, fitted_line: str, scaler_path: str, distribution_curve: str, distance_threshold: float, distribution_threshold, filtered: bool = True, visualize: bool = False, update_fits: bool = True):\n",
        "        \"\"\"\n",
        "        Filter rows from the DataFrame object to train with respect to Multiple Linear Regression fitted line and Distance Distribution.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pandas.core.frame.DataFrame\n",
        "            A pandas DataFrame object from which to filter untrained data (rows).\n",
        "        x : list[str]\n",
        "            List of column names from the DataFrame to treat as features.\n",
        "        y : str\n",
        "            The name of the column from the DataFrame to treat as target.\n",
        "        fitted_line : str\n",
        "            The file path of shadow_fit.pkl\n",
        "        scaler_path : str\n",
        "            The file path of shadow_scaler.pkl\n",
        "        distribution_curve : str\n",
        "            The file path of shadow_distribution.json\n",
        "        distance_threshold : float\n",
        "            The minimum distance to accept the row vectors from the fitted line.\n",
        "        distribution_threshold : float\n",
        "            The minimum distance from the distribution curve to accept for each distance interval.\n",
        "        filtered : bool\n",
        "            When True, return a new DataFrame object with filtered rows only, otherwise add a new column to the DataFrame object named 'SLToTrain' to the DataFrame object provided to mark the rows. True by default.\n",
        "        visualize : bool\n",
        "            When True, prints the plot of new row vectors with fitted line and the plot of distance distribution curve. False by default\n",
        "        update_fits : bool\n",
        "            When True, update the fitted line and the distnace distributions with the filtered rows. True by default.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pandas.core.frame.DataFrame\n",
        "            Filtered or marked DataFrame object.\n",
        "        list[float]\n",
        "            Updated fitted line, if update_lr = True\n",
        "        list[float]\n",
        "            Updated distance distribution curve, if update_distribution = True\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # Checking paramters are of required type\n",
        "        if not(isinstance(df, pandas.core.frame.DataFrame)):\n",
        "            raise TypeError(\"DataFrame provided is not of type pandas.core.frame.DataFrame\")\n",
        "\n",
        "        if not (isinstance(x, list) and all(isinstance(item, str) for item in x)):\n",
        "            raise TypeError(\"Provided features list is not of of type list[str]\")\n",
        "\n",
        "        if not(isinstance(y, str)):\n",
        "            raise TypeError(\"Provided target column is not of type str\")\n",
        "\n",
        "        if not(isinstance(fitted_line, str)):\n",
        "            raise TypeError(\"Fitted Line is not of type ...\")\n",
        "        else:\n",
        "            try:\n",
        "                model = load(fitted_line)\n",
        "            except FileNotFoundError:\n",
        "                raise FileNotFoundError(f\"Could not find the model file: '{fitted_line}'\")\n",
        "\n",
        "        if not(isinstance(scaler_path, str)):\n",
        "            raise TypeError(\"Fitted Line is not of type ...\")\n",
        "        else:\n",
        "            try:\n",
        "                scaler = load(scaler_path)\n",
        "            except FileNotFoundError:\n",
        "                raise FileNotFoundError(f\"Could not find the model file: '{scaler_path}'\")\n",
        "\n",
        "        if not(isinstance(distribution_curve, str)):\n",
        "            raise TypeError(\"Distribution Curve is not of type ...\")\n",
        "        else:\n",
        "            try:\n",
        "                with open(distribution_curve, 'r') as file:\n",
        "                    fitted_distribution = json.load(file)\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: The file '{distribution_curve}' doesn't exist.\")\n",
        "                return None\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error: The file '{distribution_curve}' is not valid JSON.\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred: {e}\")\n",
        "                return None\n",
        "\n",
        "        if isinstance(distance_threshold, (int, float)):\n",
        "            if not(0 <= distance_threshold <= 1):\n",
        "                raise ValueError(\"Distance Threshold should be between 0 and 1.\")\n",
        "        else:\n",
        "            raise TypeError(\"Distance Threshold should be of type int or float\")\n",
        "\n",
        "        if isinstance(distribution_threshold, (int, float)):\n",
        "            if not(0 <= distribution_threshold <= 1):\n",
        "                raise ValueError(\"Distribution Threshold should be between 0 and 1.\")\n",
        "        else:\n",
        "            raise TypeError(\"Distribution Threshold should be of type int or float\")\n",
        "\n",
        "        if not(isinstance(filtered, bool)):\n",
        "            raise TypeError(\"Filter parameter is not of type bool\")\n",
        "\n",
        "        if not(isinstance(visualize, bool)):\n",
        "            raise TypeError(\"Visualize parameter is not of type bool\")\n",
        "\n",
        "        if not(isinstance(update_fits, bool)):\n",
        "            raise TypeError(\"update_lr parameter is not of type bool\")\n",
        "\n",
        "\n",
        "        X = df[x]\n",
        "        Y = df[y]\n",
        "\n",
        "        weights = model.coef_\n",
        "        intercept = model.intercept_\n",
        "\n",
        "        numerator = numpy.abs(numpy.dot(X, weights) + intercept - Y)\n",
        "        denominator = numpy.sqrt(numpy.sum(weights ** 2))\n",
        "        distances_from_fit = numerator / denominator\n",
        "        distances_from_fit = scaler.transform(numpy.array(distances_from_fit).reshape(-1, 1))\n",
        "        distribution = self.roundToNearestBins(distances_from_fit)\n",
        "\n",
        "        df['SLToTrain'] = distances_from_fit.flatten() > distance_threshold\n",
        "\n",
        "        target_values = numpy.arange(0.000, 1.050, 0.025)\n",
        "        distribution = [round(x, 3) for x in distribution]\n",
        "\n",
        "        df['SLDistances'] = numpy.array(distribution).flatten()\n",
        "\n",
        "\n",
        "        counts_dict = {numpy.around(val, decimals=3): 0 for val in target_values}\n",
        "        counts_dict.update(Counter(distribution))\n",
        "\n",
        "        fitted_distribution = {float(k): v for k, v in fitted_distribution.items()}\n",
        "        differences = {key: abs(counts_dict[key] - fitted_distribution[key]) / counts_dict[key]\n",
        "                        if counts_dict[key] != 0\n",
        "                        else 0\n",
        "                        for key in counts_dict.keys() if key in fitted_distribution}\n",
        "\n",
        "        df[\"SLToTrain\"] = df[\"SLDistances\"].apply(\n",
        "            lambda x: any(differences.get(bin_key, 0) > distribution_threshold for bin_key in [x])\n",
        "        )\n",
        "\n",
        "\n",
        "        if update_fits:\n",
        "            self.fit(df, x, y)\n",
        "\n",
        "        if visualize:\n",
        "            self.visualizing(fitted_distribution, counts_dict)\n",
        "\n",
        "        if filtered:\n",
        "            filtered_df = df[df['SLToTrain'] == True]\n",
        "            filtered_df = filtered_df.copy()\n",
        "            filtered_df.drop(columns=[\"SLToTrain\", \"SLDistances\"], inplace=True)\n",
        "            return filtered_df\n",
        "        else:\n",
        "            df.drop(columns=[\"SLDistances\"], inplace=True)\n",
        "            return df\n",
        "\n",
        "    def visualizing(self, first_distribution, second_distribution):\n",
        "        # Example dictionaries\n",
        "        dict1 = first_distribution\n",
        "        dict2 = second_distribution\n",
        "\n",
        "        keys = list(dict1.keys())\n",
        "        values1 = list(dict1.values())\n",
        "        values2 = list(dict2.values())\n",
        "\n",
        "        # Define bar positions\n",
        "        x = numpy.arange(len(keys))  # Positions for the bars\n",
        "        width = 0.35  # Width of the bars\n",
        "\n",
        "        # Plotting\n",
        "        fig, ax = plt.subplots()\n",
        "        bar1 = ax.bar(x - width/2, values1, width, label='Fitted Distribution', color='lightblue')\n",
        "        bar2 = ax.bar(x + width/2, values2, width, label='New Distribution', color='steelblue')\n",
        "\n",
        "        # Adding labels and title\n",
        "        ax.set_xlabel('Bins')\n",
        "        ax.set_ylabel('Frequency')\n",
        "        ax.set_title('Fitted vs. New Distribution')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(keys, rotation=90)  # Tilt x-axis labels 90 degrees\n",
        "        ax.legend()\n",
        "\n",
        "        for bar in bar1:\n",
        "            height = bar.get_height()\n",
        "            ax.text(\n",
        "                bar.get_x() + bar.get_width()/2, height + 0.05,  # Position\n",
        "                f'{height}', ha='center', va='bottom', fontsize=5\n",
        "            )\n",
        "\n",
        "        for bar in bar2:\n",
        "            height = bar.get_height()\n",
        "            ax.text(\n",
        "                bar.get_x() + bar.get_width()/2, height + 0.05,  # Position\n",
        "                f'{height}', ha='center', va='bottom', fontsize=5\n",
        "            )\n",
        "\n",
        "        # Display the plot\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################################\n",
        "###     TESTING     ###\n",
        "# df  = pandas.read_csv('random_dataframe.csv')\n",
        "df  = pandas.read_csv('random2.csv')\n",
        "# df  = 541\n",
        "x = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\n",
        "# x = 50\n",
        "y = 'target'\n",
        "# y = 0.0\n",
        "fitted = 'shadow_fit.pkl'\n",
        "scale = 'shadow_scaler.pkl'\n",
        "curve = 'shadow_distribution.json'\n",
        "dist = 0.521\n",
        "distri = 0.62\n",
        "filter_ = False\n",
        "visi = True\n",
        "ulr = True\n",
        "udist = True\n",
        "\n",
        "\n",
        "sl = ShadowLearning()\n",
        "# sl.fit(df, x, y)\n",
        "# output = sl.filter(df, x, y, fitted, scale, curve, dist, distri, filter_, visi, update_fits=False)\n",
        "# print(output)\n",
        "\n",
        "###     TESTING     ###\n",
        "###################################################################"
      ],
      "metadata": {
        "id": "AZ9Ra5kRYUgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}